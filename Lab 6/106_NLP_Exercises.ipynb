{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Exercises\n",
    "\n",
    "We have five exercises in this section. The exercises are:\n",
    "1. Build your own tokenizer, where you need to implement two functions to implement a tokenizer based on regular expression.\n",
    "2. Get tags from Trump speech.\n",
    "3. Get the nouns in the last 10 sentences from Trump's speech and find the nouns divided by sentencens. Use SpaCy.\n",
    "4. Build your own Bag Of Words implementation using tokenizer created before.\n",
    "5. Build a 5-gram model and clean up the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. Build your own tokenizer\n",
    "\n",
    "Build two different tokenizers:\n",
    "- ``tokenize_sentence``: function tokenizing text into sentences,\n",
    "- ``tokenize_word``: function tokenizing text into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized sentences:\n",
      "['Here we go again.', ' I was supposed to add this text later.', \"Well, it's 10.\", 'p.', 'm.', \" here, and I'm actually having fun making this course.\", ' :oI hope you are getting along fine with this presentation, I really did try.', 'And one last sentence, just so you can test you tokenizers better.', '']\n",
      "\n",
      "Tokenized words:\n",
      "['Here', 'we', 'go', 'again', 'I', 'was', 'supposed', 'to', 'add', 'this', 'text', 'later', 'Well', 'it', 's', '10', 'p', 'm', 'here', 'and', 'I', 'm', 'actually', 'having', 'fun', 'making', 'this', 'course', 'oI', 'hope', 'you', 'are', 'getting', 'along', 'fine', 'with', 'this', 'presentation', 'I', 'really', 'did', 'try', 'And', 'one', 'last', 'sentence', 'just', 'so', 'you', 'can', 'test', 'you', 'tokenizers', 'better', '']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re \n",
    "from typing import List\n",
    "\n",
    "def tokenize_words(text: str) -> list:\n",
    "    list_of_words = re.split(r'\\W+', text)   # Matches any character which is not a word character.\n",
    "    return list_of_words\n",
    "\n",
    "def tokenize_sentence(text: str) -> list:\n",
    "    list_of_sentences =  re.split('(?<=[.!?])',text)   \n",
    "    return list_of_sentences\n",
    "\n",
    "text = \"Here we go again. I was supposed to add this text later.\\\n",
    "Well, it's 10.p.m. here, and I'm actually having fun making this course. :o\\\n",
    "I hope you are getting along fine with this presentation, I really did try.\\\n",
    "And one last sentence, just so you can test you tokenizers better.\"\n",
    "\n",
    "print(\"\\nTokenized sentences:\")\n",
    "print(tokenize_sentence(text))\n",
    "print(\"\\nTokenized words:\")\n",
    "print(tokenize_words(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. Get tags from Trump speech using NLTK\n",
    "\n",
    "You should use the ``trump.txt`` file, read it and find the tags for each word. Use NLTK for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " (',', ','),\n",
       " ('everybody', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('very', 'RB'),\n",
       " ('much', 'RB'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " (',', ','),\n",
       " ('Matt', 'NNP'),\n",
       " (',', ','),\n",
       " ('for', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('introduction', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('thank', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('for', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('crowd', 'NN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('incredible', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Really', 'RB'),\n",
       " ('incredible', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('all', 'DT'),\n",
       " ('come', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('long', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('together', 'RB'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('come', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('long', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('together', 'RB'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('m', 'RB'),\n",
       " ('thrilled', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('back', 'RB'),\n",
       " ('at', 'IN'),\n",
       " ('CPAC', 'NNP'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('so', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('wonderful', 'JJ'),\n",
       " ('friends', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('amazing', 'JJ'),\n",
       " ('supporters', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('proud', 'JJ'),\n",
       " ('conservatives', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Remember', 'NNP'),\n",
       " ('when', 'WRB'),\n",
       " ('I', 'PRP'),\n",
       " ('first', 'RB'),\n",
       " ('started', 'VBD'),\n",
       " ('running', 'VBG'),\n",
       " ('?', '.'),\n",
       " ('Because', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('wasn', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('politician', 'NN'),\n",
       " (',', ','),\n",
       " ('fortunately', 'RB'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('do', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('remember', 'VB'),\n",
       " ('I', 'PRP'),\n",
       " ('started', 'VBD'),\n",
       " ('running', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('people', 'NNS'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('sure', 'JJ'),\n",
       " ('he', 'PRP'),\n",
       " ('’', 'VBZ'),\n",
       " ('s', 'PDT'),\n",
       " ('a', 'DT'),\n",
       " ('conservative', 'JJ'),\n",
       " ('?', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('think', 'VBP'),\n",
       " ('I', 'PRP'),\n",
       " ('proved', 'VBD'),\n",
       " ('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('m', 'PDT'),\n",
       " ('a', 'DT'),\n",
       " ('conservative', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('For', 'IN'),\n",
       " ('more', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('four', 'CD'),\n",
       " ('decades', 'NNS'),\n",
       " (',', ','),\n",
       " ('this', 'DT'),\n",
       " ('event', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('served', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('forum', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('nation', 'NN'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('top', 'JJ'),\n",
       " ('leaders', 'NNS'),\n",
       " (',', ','),\n",
       " ('activists', 'NNS'),\n",
       " (',', ','),\n",
       " ('writers', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('thinkers', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Year', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('year', 'NN'),\n",
       " (',', ','),\n",
       " ('leaders', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('stood', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('stage', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('discuss', 'VB'),\n",
       " ('what', 'WP'),\n",
       " ('we', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('do', 'VB'),\n",
       " ('together', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('protect', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('heritage', 'NN'),\n",
       " (',', ','),\n",
       " ('to', 'TO'),\n",
       " ('promote', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('culture', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('to', 'TO'),\n",
       " ('defend', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('freedom', 'NN'),\n",
       " ('.', '.'),\n",
       " ('CPAC', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('always', 'RB'),\n",
       " ('been', 'VBN'),\n",
       " ('about', 'RB'),\n",
       " ('big', 'JJ'),\n",
       " ('ideas', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('also', 'RB'),\n",
       " ('been', 'VBN'),\n",
       " ('about', 'IN'),\n",
       " ('putting', 'VBG'),\n",
       " ('those', 'DT'),\n",
       " ('ideas', 'NNS'),\n",
       " ('into', 'IN'),\n",
       " ('action', 'NN'),\n",
       " ('—', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('CPAC', 'NNP'),\n",
       " ('really', 'RB'),\n",
       " ('has', 'VBZ'),\n",
       " ('put', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('ideas', 'NNS'),\n",
       " ('into', 'IN'),\n",
       " ('action', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ll', 'JJ'),\n",
       " ('talk', 'NN'),\n",
       " ('about', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('this', 'DT'),\n",
       " ('morning', 'NN'),\n",
       " ('.', '.'),\n",
       " ('For', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('last', 'JJ'),\n",
       " ('year', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('help', 'NN'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('put', 'VBN'),\n",
       " ('more', 'JJR'),\n",
       " ('great', 'JJ'),\n",
       " ('conservative', 'JJ'),\n",
       " ('ideas', 'NNS'),\n",
       " ('into', 'IN'),\n",
       " ('use', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('perhaps', 'RB'),\n",
       " ('ever', 'RB'),\n",
       " ('before', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('American', 'JJ'),\n",
       " ('history', 'NN'),\n",
       " ('.', '.'),\n",
       " ('What', 'WP'),\n",
       " ('a', 'DT'),\n",
       " ('nice', 'JJ'),\n",
       " ('picture', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('.', '.'),\n",
       " ('Look', 'VB'),\n",
       " ('at', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('love', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('watch', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('guy', 'NN'),\n",
       " ('speak', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Oh', 'UH'),\n",
       " (',', ','),\n",
       " ('boy', 'UH'),\n",
       " ('.', '.'),\n",
       " ('Oh', 'UH'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('try', 'VBP'),\n",
       " ('like', 'IN'),\n",
       " ('hell', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('hide', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('bald', 'NN'),\n",
       " ('spot', 'NN'),\n",
       " (',', ','),\n",
       " ('folks', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('work', 'VBP'),\n",
       " ('hard', 'RB'),\n",
       " ('at', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Doesn', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('t', 'VBD'),\n",
       " ('look', 'NN'),\n",
       " ('bad', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Hey', 'NNP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'JJ'),\n",
       " ('hanging', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'JJ'),\n",
       " ('hanging', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'JJ'),\n",
       " ('hanging', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('there', 'RB'),\n",
       " (',', ','),\n",
       " ('right', 'RB'),\n",
       " ('?', '.'),\n",
       " ('Together', 'RB'),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'JJ'),\n",
       " ('hanging', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('confirmed', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('record', 'NN'),\n",
       " ('number', 'NN'),\n",
       " (',', ','),\n",
       " ('so', 'RB'),\n",
       " ('important', 'JJ'),\n",
       " (',', ','),\n",
       " ('of', 'IN'),\n",
       " ('circuit', 'NN'),\n",
       " ('court', 'NN'),\n",
       " ('judges', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'RB'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('putting', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('more', 'JJR'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('they', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('interpret', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('law', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('written', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('confirmed', 'VBN'),\n",
       " ('an', 'DT'),\n",
       " ('incredible', 'JJ'),\n",
       " ('new', 'JJ'),\n",
       " ('Supreme', 'NNP'),\n",
       " ('Court', 'NNP'),\n",
       " ('justice', 'NN'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('man', 'NN'),\n",
       " (',', ','),\n",
       " ('Neil', 'NNP'),\n",
       " ('Gorsuch', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Right', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('passed', 'VBN'),\n",
       " ('massive', 'JJ'),\n",
       " (',', ','),\n",
       " ('biggest', 'JJS'),\n",
       " ('in', 'IN'),\n",
       " ('history', 'NN'),\n",
       " (',', ','),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('reforms', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('don', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('use', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('word', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('reform', 'NN'),\n",
       " ('too', 'RB'),\n",
       " (',', ','),\n",
       " ('very', 'RB'),\n",
       " ('positive', 'JJ'),\n",
       " ('—', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('don', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('when', 'WRB'),\n",
       " ('we', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('first', 'RB'),\n",
       " ('doing', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('I', 'PRP'),\n",
       " ('told', 'VBD'),\n",
       " ('everybody', 'NN'),\n",
       " (',', ','),\n",
       " ('everybody', 'NN'),\n",
       " ('gathered', 'VBD'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('just', 'RB'),\n",
       " ('talk', 'VB'),\n",
       " ('about', 'IN'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('People', 'NNS'),\n",
       " ('don', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('know', 'VBP'),\n",
       " ('what', 'WP'),\n",
       " ('reform', 'NN'),\n",
       " ('means', 'VBZ'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('think', 'VBP'),\n",
       " ('reform', 'NN'),\n",
       " ('might', 'MD'),\n",
       " ('mean', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('going', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('do', 'VBP'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('How', 'WRB'),\n",
       " ('did', 'VBD'),\n",
       " ('he', 'PRP'),\n",
       " ('get', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('here', 'RB'),\n",
       " (',', ','),\n",
       " ('Matt', 'NNP'),\n",
       " ('?', '.'),\n",
       " ('Boy', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Okay', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Just', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('media', 'NNS'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('fake', 'JJ'),\n",
       " ('news', 'NN'),\n",
       " ('back', 'RB'),\n",
       " ('there', 'RB'),\n",
       " (',', ','),\n",
       " ('they', 'PRP'),\n",
       " ('took', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('care', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('him', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('gentle', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('obnoxious', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('only', 'RB'),\n",
       " ('one', 'CD'),\n",
       " ('person', 'NN'),\n",
       " ('.', '.'),\n",
       " ('So', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('thousands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('people', 'NNS'),\n",
       " ('here', 'RB'),\n",
       " ('.', '.'),\n",
       " ('So', 'RB'),\n",
       " (',', ','),\n",
       " ('listen', 'UH'),\n",
       " (',', ','),\n",
       " ('tomorrow', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('headline', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('protesters', 'NNS'),\n",
       " ('disturb', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('Trump', 'NNP'),\n",
       " ('—', 'NNP'),\n",
       " ('one', 'CD'),\n",
       " ('person', 'NN'),\n",
       " (',', ','),\n",
       " ('folks', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Doesn', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('deserve', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('mention', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Doesn', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('deserve', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('headline', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('headline', 'NN'),\n",
       " ('tomorrow', 'NN'),\n",
       " (',', ','),\n",
       " ('disrupters', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('CPAC', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('One', 'CD'),\n",
       " ('person', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('he', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('nice', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('looked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('him', 'PRP'),\n",
       " (',', ','),\n",
       " ('he', 'PRP'),\n",
       " ('immediately', 'RB'),\n",
       " ('left', 'VBD'),\n",
       " ('.', '.'),\n",
       " ('Okay', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Now', 'RB'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ve', 'RB'),\n",
       " ('heard', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('too', 'RB'),\n",
       " ('often', 'RB'),\n",
       " ('.', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ll', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('one', 'CD'),\n",
       " ('person', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('you', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('hardly', 'RB'),\n",
       " ('even', 'RB'),\n",
       " ('hear', 'VBP'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('biggest', 'JJS'),\n",
       " ('disturbance', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('people', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " ('why', 'WRB'),\n",
       " ('?', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('’', 'VBZ'),\n",
       " ('ll', 'NNS'),\n",
       " ('say', 'VBP'),\n",
       " ('something', 'NN'),\n",
       " (',', ','),\n",
       " ('nobody', 'NN'),\n",
       " ('hears', 'VBZ'),\n",
       " ('him', 'PRP'),\n",
       " (',', ','),\n",
       " ('because', 'IN'),\n",
       " ('—', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('crowd', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('start', 'VB'),\n",
       " ('screaming', 'VBG'),\n",
       " ('at', 'IN'),\n",
       " ('him', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('all', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('sudden', 'JJ'),\n",
       " ('we', 'PRP'),\n",
       " ('start', 'VBP'),\n",
       " ('—', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('that', 'DT'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('okay', 'RP'),\n",
       " ('.', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('show', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('spirit', 'NN'),\n",
       " (',', ','),\n",
       " ('right', 'RB'),\n",
       " ('?', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('show', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('spirit', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('true', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('So', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('passed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('biggest', 'JJS'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('history', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('country', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('called', 'VBN'),\n",
       " ('tax', 'NN'),\n",
       " ('cut', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('reform', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('our', 'PRP$'),\n",
       " ('people', 'NNS'),\n",
       " (',', ','),\n",
       " ('don', 'JJ'),\n",
       " ('’', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('word', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Because', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'RB'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('go', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('tax', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('no', 'DT'),\n",
       " ('wonder', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('45', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('nothing', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('passed', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('Because', 'IN'),\n",
       " ('people', 'NNS'),\n",
       " ('want', 'VBP'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('they', 'PRP'),\n",
       " ('don', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('know', 'VBP'),\n",
       " ('what', 'WP'),\n",
       " ('reform', 'NN'),\n",
       " ('means', 'VBZ'),\n",
       " ('.', '.'),\n",
       " ('Reform', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('mean', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'VB'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('pay', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('tax', 'NN'),\n",
       " ('.', '.'),\n",
       " ('So', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('convinced', 'VBP'),\n",
       " ('politicians', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('have', 'VBP'),\n",
       " ('done', 'VBN'),\n",
       " ('this', 'DT'),\n",
       " ('all', 'DT'),\n",
       " ('their', 'PRP$'),\n",
       " ('lives', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('they', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('job', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('many', 'JJ'),\n",
       " ('cases', 'NNS'),\n",
       " (',', ','),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('—', 'PDT'),\n",
       " ('the', 'DT'),\n",
       " ('tax', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('whatever', 'WDT'),\n",
       " ('year', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('put', 'VB'),\n",
       " (',', ','),\n",
       " ('okay', 'NN'),\n",
       " ('.', '.'),\n",
       " ('So', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('tax', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('that', 'DT'),\n",
       " ('was', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('called', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('tax', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('tax', 'NN'),\n",
       " ('cut', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('jobs', 'NNS'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('add', 'VB'),\n",
       " ('jobs', 'NNS'),\n",
       " ('into', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " (',', ','),\n",
       " ('because', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'NNS'),\n",
       " ('picking', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('tremendous', 'JJ'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('jobs', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('2.7', 'CD'),\n",
       " ('million', 'CD'),\n",
       " ('jobs', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('2.7', 'CD'),\n",
       " ('.', '.'),\n",
       " ('So', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('people', 'NNS'),\n",
       " ('hear', 'VBP'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('popular', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Remember', 'NNP'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " ('started', 'VBD'),\n",
       " ('off', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('slow', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Then', 'RB'),\n",
       " ('it', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('passed', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('some', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('help', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('say', 'VB'),\n",
       " ('we', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('some', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('help', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Senate', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('House', 'NNP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('guys', 'VBN'),\n",
       " ('here', 'RB'),\n",
       " ('today', 'NN'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Congressmen', 'NNP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('senators', 'NNS'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('help', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('passed', 'VBD'),\n",
       " (',', ','),\n",
       " ('just', 'RB'),\n",
       " ('—', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('easy', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('didn', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('one', 'CD'),\n",
       " ('Democrat', 'NNP'),\n",
       " ('vote', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('think', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('’', 'VBP'),\n",
       " ('s', 'VB'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('cost', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('midterms', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('whoever', 'WP'),\n",
       " ('wins', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('presidency', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('disadvantage', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('whatever', 'WDT'),\n",
       " ('reason', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('midterms', 'NNS'),\n",
       " ('.', '.'),\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize  # exercise 2\n",
    "from nltk import pos_tag        # exercise 2\n",
    "\n",
    "file = open(\"./datasets/trump.txt\", \"r\",encoding=\"utf-8\") \n",
    "trump = file.read()\n",
    "#words = tokenize_words(trump)\n",
    "words = word_tokenize(trump)\n",
    "\n",
    "tagged_words = pos_tag(words)\n",
    "tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3. Get the nouns in the last 10 sentences from Trump's speech and find the nouns divided by sentencens. Use SpaCy.\n",
    "\n",
    "Please use Python list features to get the last 10 sentences and display nouns from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will see.Hopefully something positive can happen.But that just was announced and I wanted to let you know.We have imposed the heaviest sanctions ever imposed.So ladies and gentlemen, thank you for everything.You’ve been incredible partners.Incredible partners.And I will let you know in the absolute strongest of terms, we’re going to make America great again and I will never, ever, ever let you down.Thank you very much.Thank you.\n",
      "\n",
      "\n",
      "nouns divided by sentencens : 0.9\n"
     ]
    }
   ],
   "source": [
    "import spacy   # exercise 3\n",
    "from nltk.tokenize import sent_tokenize  # exercise 3\n",
    "\n",
    "file = open(\"./datasets/trump.txt\", \"r\",encoding='utf-8') \n",
    "trump = file.read() \n",
    "tokenized_trump = sent_tokenize(trump)\n",
    "tokenized_trump = tokenized_trump[len(tokenized_trump)-10 : ]\n",
    "trump = ''.join(tokenized_trump)\n",
    "\n",
    "print(trump)\n",
    "\n",
    "number_of_sentenses = 10\n",
    "number_of_nouns = 0\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(trump)\n",
    "\n",
    "for token in doc:\n",
    "    #print(\"> \",token.text,token.pos_)\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        number_of_nouns = number_of_nouns + 1\n",
    "\n",
    "print(\"\\n\\nnouns divided by sentencens : {:}\".format(number_of_nouns / number_of_sentenses) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4. Build your own Bag Of Words implementation using tokenizer created before \n",
    "\n",
    "You need to implement following methods:\n",
    "\n",
    "- ``fit_transform`` - gets a list of strings and returns matrix with it's BoW representation\n",
    "- ``get_features_names`` - returns list of words corresponding to columns in BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN FT TRANSFORM\n",
      "[[0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1]\n",
      " [0 0 0 1 1 0 1 0 2 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 2 1 0 0 0 1 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>As</th>\n",
       "      <th>Bag</th>\n",
       "      <th>Of</th>\n",
       "      <th>Really</th>\n",
       "      <th>This</th>\n",
       "      <th>Words</th>\n",
       "      <th>a</th>\n",
       "      <th>based</th>\n",
       "      <th>below</th>\n",
       "      <th>can</th>\n",
       "      <th>...</th>\n",
       "      <th>only</th>\n",
       "      <th>pretty</th>\n",
       "      <th>see</th>\n",
       "      <th>sparse</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>throughout</th>\n",
       "      <th>us</th>\n",
       "      <th>words</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   As  Bag  Of  Really  This  Words  a  based  below  can ...   only  pretty  \\\n",
       "0   0    1   1       0     0      1  0      1      0    0 ...      0       0   \n",
       "1   0    0   0       0     0      0  0      0      0    0 ...      0       0   \n",
       "2   0    0   0       0     1      0  0      0      0    0 ...      0       0   \n",
       "3   1    0   0       0     0      0  0      0      0    1 ...      1       0   \n",
       "4   0    0   0       1     1      0  1      0      2    0 ...      0       1   \n",
       "\n",
       "   see  sparse  the  third  throughout  us  words  you  \n",
       "0    0       0    0      0           0   0      0    0  \n",
       "1    0       0    0      0           1   0      1    0  \n",
       "2    0       0    1      1           0   0      0    0  \n",
       "3    1       0    1      0           0   0      1    1  \n",
       "4    2       1    0      0           0   1      0    0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "class BagOfWords:\n",
    "    \"\"\"Basic BoW implementation.\"\"\"\n",
    "    \n",
    "    __nlp = spacy.load(\"en_core_web_sm\")\n",
    "    __bow_list = []\n",
    "    __list_of_sentences = []\n",
    "    __list_of_words = []\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, corpus: list):\n",
    "        \"\"\"Transform list of strings into BoW array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus: List[str]\n",
    "                Corpus of texts to be transforrmed\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "                Matrix representation of BoW\n",
    "        \"\"\"\n",
    "        print(\"IN FT TRANSFORM\")\n",
    "              \n",
    "        self.__list_of_sentences = corpus\n",
    "        \n",
    "        \n",
    "        for s in self.__list_of_sentences:          \n",
    "            for word in tokenize_words(s):\n",
    "                self.__list_of_words.append(word)\n",
    "                \n",
    "        self.__list_of_words = list(set(self.__list_of_words))\n",
    "        self.__list_of_words.sort()   \n",
    "        if self.__list_of_words[0] == '':\n",
    "            self.__list_of_words.pop(0)\n",
    "    \n",
    "        for s in self.__list_of_sentences:\n",
    "            tmp = []\n",
    "            for low in self.__list_of_words:\n",
    "                counter = 0\n",
    "                for w in tokenize_words(s):\n",
    "                    if w == low:\n",
    "                        counter = counter+1\n",
    "                tmp.append(counter)           \n",
    "            self.__bow_list.append(tmp)        \n",
    "        return np.array(self.__bow_list)\n",
    "         \n",
    "\n",
    "    def get_feature_names(self) -> list:\n",
    "        return self.__list_of_words\n",
    "\n",
    "corpus = [\n",
    "     'Bag Of Words is based on counting',\n",
    "     'words occurences throughout multiple documents.',\n",
    "     'This is the third document.',\n",
    "     'As you can see most of the words occur only once.',\n",
    "     'This gives us a pretty sparse matrix, see below. Really, see below']    \n",
    "    \n",
    "vectorizer = BagOfWords()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)\n",
    "\n",
    "names = vectorizer.get_feature_names()\n",
    "len(vectorizer.get_feature_names())\n",
    "\n",
    "df = pd.DataFrame(X, columns= names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5. Build a 5-gram model and clean up the results.\n",
    "\n",
    "There are three tasks to do:\n",
    "1. Use 5-gram model instead of 3.\n",
    "2. Change to capital letter each first letter of a sentence.\n",
    "3. Remove the whitespace between the last word in a sentence and . ! or ?.\n",
    "\n",
    "Hint: for 2. and 3. implement a function called ``clean_generated()`` that takes the generated text and fix both issues at once. It could be easier to fix the text after it's generated rather then doing some changes in the while loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from numpy.random import random, randint\n",
    "from nltk.book import *\n",
    "\n",
    "wall_street = text7.tokens\n",
    "tokens = wall_street\n",
    "\n",
    "def cleanup():\n",
    "    compiled_pattern = re.compile(\"^[a-zA-Z0-9.!?]\")\n",
    "    clean = list(filter(compiled_pattern.match,tokens))\n",
    "    return clean\n",
    "tokens = cleanup()\n",
    "\n",
    "def build_ngrams():\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens)-N+1):\n",
    "        ngrams.append(tokens[i:i+N])\n",
    "    return ngrams\n",
    "\n",
    "def ngram_freqs(ngrams):\n",
    "    counts = {}\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        token_seq  = SEP.join(ngram[:-1])\n",
    "        last_token = ngram[-1]\n",
    "\n",
    "        if token_seq not in counts:\n",
    "            counts[token_seq] = {}\n",
    "\n",
    "        if last_token not in counts[token_seq]:\n",
    "            counts[token_seq][last_token] = 0\n",
    "\n",
    "        counts[token_seq][last_token] += 1;\n",
    "    return counts\n",
    "\n",
    "def next_word(text, N, counts):\n",
    "\n",
    "    token_seq = SEP.join(text.split()[-(N-1):]);\n",
    "    choices = counts[token_seq].items();\n",
    "\n",
    "    total = sum(weight for choice, weight in choices)\n",
    "    r = random.uniform(0, total)\n",
    "    upto = 0\n",
    "    for choice, weight in choices:\n",
    "        upto += weight;\n",
    "        if upto > r: return choice\n",
    "    assert False # should not reach here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Before:\n",
      " we have managed to maximize our direct-mail capability . In addition Buick is a relatively respected nameplate among American Express card holders says 0 an American Express spokeswoman . When the company asked members in a mailing which cars they would like to be the company next chief executive . Mr. Baum said 0 the two have orders to focus on bottom-line profits and to take a hard look at our businesses what is good what is not so good . Analysts generally applaud the performance of Campbell U.S.A. the company largest division which posted 6 unit sales growth and a 15 improvement in operating profit for fiscal 1989 . The House and Senate are divided over whether the United Nations Population Fund will receive any portion of these appropriations but the size of the charge until they determine which employees and how many will participate in the retirement plan . But the pharmaceutical company said 0 it believes 0 would perform satisfactorily on the bench . In contrast the lawyers association gives a well qualified rating to those regarded as one of the last women 0 to be executed in France and as a symbol of the Vichy government hypocrisy .\n",
      "\n",
      "\n",
      "After:\n",
      " We have managed to maximize our direct-mail capability. In addition Buick is a relatively respected nameplate among American Express card holders says 0 an American Express spokeswoman. When the company asked members in a mailing which cars they would like to be the company next chief executive. Mr. Baum said 0 the two have orders to focus on bottom-line profits and to take a hard look at our businesses what is good what is not so good. Analysts generally applaud the performance of Campbell U.S.A. the company largest division which posted 6 unit sales growth and a 15 improvement in operating profit for fiscal 1989. The House and Senate are divided over whether the United Nations Population Fund will receive any portion of these appropriations but the size of the charge until they determine which employees and how many will participate in the retirement plan. But the pharmaceutical company said 0 it believes 0 would perform satisfactorily on the bench. In contrast the lawyers association gives a well qualified rating to those regarded as one of the last women 0 to be executed in France and as a symbol of the Vichy government hypocrisy.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def clean_generated(generated):\n",
    "    \n",
    "    tmp = []\n",
    "    generated = generated.replace(\" .\", \".\").replace(\" ?\", \"?\").replace(\" !\", \"!\") \n",
    "    \n",
    "    for g in generated:\n",
    "        tmp.append(g)\n",
    "\n",
    "    tmp[0] = tmp[0].upper()\n",
    "        \n",
    "    return \"\".join(tmp)\n",
    "\n",
    "\n",
    "N=5\n",
    "SEP=\" \"\n",
    "sentence_count=10\n",
    "\n",
    "ngrams = build_ngrams()\n",
    "start_seq=\"we have managed to\"\n",
    "\n",
    "counts = ngram_freqs(ngrams)\n",
    "\n",
    "if start_seq is None: start_seq = random.choice(list(counts.keys()))\n",
    "generated = start_seq.lower();\n",
    "\n",
    "sentences = 0\n",
    "while sentences < sentence_count:\n",
    "    generated += SEP + next_word(generated, N, counts)\n",
    "    sentences += 1 if generated.endswith(('.','!', '?')) else 0\n",
    "\n",
    "print(\"\\n\\nBefore:\\n\",generated)\n",
    "\n",
    "generated = clean_generated(generated)\n",
    "\n",
    "print(\"\\n\\nAfter:\\n\",generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
